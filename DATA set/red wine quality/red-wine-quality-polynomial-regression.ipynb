{"cells":[{"metadata":{"_uuid":"015a922af8e5728bfd9ec19a9f31835e2502c5e0","_cell_guid":"d83cf61f-3a73-4f16-b7ec-b11b26afbd74","trusted":true},"cell_type":"code","source":"# In the previous kernal for the same data-set \"winequality-red.csv\", the mean-squared error of the\n# predictor is 0.475(approx), which was performed in Linear Regression. To reduce the mean error the\n# model was predicted usinh polynomial regression and the error was reduced.\n\n# Import the following packages pandas, numpy and sklearn.\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nimport matplotlib.pyplot as plt\n\n# Load the data-set.\ndf = pd.read_csv('../input/winequality-red.csv')\n\n# Quality the parameter to be predicted is represented as X.\nX = df[['quality']]\n# All the input parameters used to predict the value are represented as y.\ny = df[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']]\n\n# Data-set is divided into test data and train data based on test_size variable.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Fit the training data into polynomial model of degree 4 (appropriate value as per the data-set).\nmodel = PolynomialFeatures(degree= 4)\ny_ = model.fit_transform(y)\ny_test_ = model.fit_transform(y_test)\n\n# Fit and predict the obtained polynomial model into linear regression.\n# To Understand the relation between linear and polynomial regression visit the below link.\n# http://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions\nlg = LinearRegression()\nlg.fit(y_,X)\npredicted_data = lg.predict(y_test_)\npredicted_data = np.round_(predicted_data)\n\n# Display the mean squared error between the predicted data and test data.\nprint (mean_squared_error(X_test,predicted_data))\n# Display the values of predicted_data\nprint (predicted_data)\n\n# As seen the mean_squared_error is reduced to 0.05 far less than that of linear regressions 0.475.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}